{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24b98369-c7ba-450b-a8b5-e34319000695",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Python for Data Science\n",
    "## Session 5 \n",
    "### Basic Libraries II"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ace1343-d73d-466d-aa07-56febbb7cbf1",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ffee69-5d4d-4f1c-9ed7-083afbc931ec",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Outline\n",
    "\n",
    "1. Json, pickle and parquet formats\n",
    "\n",
    "2. Re library\n",
    "\n",
    "3. Time and Datetime libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6251cfb0",
   "metadata": {},
   "source": [
    "在 Python 中，常用的三种数据格式分别是 JSON、Pickle 和 Parquet。每种格式都有其独特的优缺点和适合的使用场景。以下是对它们的详细分析：\n",
    "\n",
    "1. JSON (JavaScript Object Notation)\n",
    "定义：JSON 是一种轻量级的数据交换格式，常用于存储和交换结构化数据，尤其是应用程序与 API 之间。\n",
    "使用场景：\n",
    "Web 应用程序：JSON 是前后端数据交互的首选格式。\n",
    "配置文件：可以用来存储程序的配置信息和元数据。\n",
    "序列化简单对象：适用于字符串、列表、字典等简单结构。\n",
    "优点：\n",
    "人类可读：JSON 是纯文本格式，便于人类阅读和编辑。\n",
    "跨语言支持：JSON 被大多数编程语言所支持，易于跨平台共享数据。\n",
    "轻量：数据格式简单，便于在网络中快速传输。\n",
    "缺点：\n",
    "复杂对象不易序列化：对于 Python 特有的数据类型（如集合或类对象），需要额外处理。\n",
    "文件较大：JSON 文件没有压缩，数据量较大时存储效率低。\n",
    "2. Pickle\n",
    "定义：Pickle 是 Python 的对象序列化工具，可以将 Python 对象存储为二进制文件，方便后续的加载。\n",
    "使用场景：\n",
    "序列化 Python 对象：适合存储任意 Python 对象，包括列表、字典、类实例等复杂对象。\n",
    "机器学习模型存储：通常用来保存训练好的机器学习模型，便于之后加载再使用。\n",
    "优点：\n",
    "支持复杂对象：可以序列化任何 Python 对象，包括自定义类、嵌套数据结构。\n",
    "易于使用：pickle 的 API 非常简单，序列化和反序列化操作都很方便。\n",
    "缺点：\n",
    "安全性问题：Pickle 文件可能包含恶意代码，不要加载不信任来源的文件。\n",
    "不跨语言：Pickle 格式只适用于 Python，不适合跨平台或跨语言的场景。\n",
    "3. Parquet\n",
    "定义：Parquet 是一种专门用于数据分析和存储的列式存储格式，通常用于大数据场景。\n",
    "使用场景：\n",
    "大数据存储：适用于数据量较大的分析任务，尤其是在数据仓库或数据湖中。\n",
    "数据分析和查询：通常与大数据处理工具（如 Apache Spark、Hadoop）配合使用。\n",
    "优点：\n",
    "列式存储：便于压缩和高效读取，特别适合于读取特定列的场景。\n",
    "高压缩率：Parquet 支持多种压缩算法，因此在存储空间和 IO 效率方面具有很大优势。\n",
    "兼容性：支持多种数据处理工具，特别适合在分布式计算环境中使用。\n",
    "缺点：\n",
    "复杂性：与 JSON 和 Pickle 相比，操作 Parquet 文件的过程更复杂，需要借助库如 pyarrow 或 pandas。\n",
    "不便于人类阅读：Parquet 是一种二进制格式，不像 JSON 那样容易阅读。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a52e250",
   "metadata": {},
   "source": [
    "re.match() 适合匹配字符串的开始部分。\n",
    "re.search() 在整个字符串中查找第一次匹配。\n",
    "re.findall() 查找所有匹配的部分并返回列表。\n",
    "re.sub() 用于替换匹配的字符串内容。\n",
    "3. 正则表达式基本语法\n",
    "3.1 常见的元字符：\n",
    ".：匹配任意字符（除换行符）\n",
    "^：匹配字符串的开始位置\n",
    "$：匹配字符串的结束位置\n",
    "*：匹配前面的字符零次或多次\n",
    "+：匹配前面的字符一次或多次\n",
    "?：匹配前面的字符零次或一次\n",
    "[]：匹配括号中的任意字符（例如 [a-z] 表示匹配所有小写字母）\n",
    "|：匹配左或右的表达式（例如 a|b）\n",
    "3.2 常见的预定义字符集：\n",
    "\\d：匹配数字，等价于 [0-9]\n",
    "\\D：匹配非数字字符\n",
    "\\w：匹配字母、数字、下划线，等价于 [a-zA-Z0-9_]\n",
    "\\W：匹配非字母、数字、下划线\n",
    "\\s：匹配空白字符（如空格、制表符）\n",
    "\\S：匹配非空白字符"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba315f4-e9bf-4a66-b3d3-593037c3ca70",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed45dcb-2cf5-4bfa-ba6e-5da25c59757c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Basic Libraries II\n",
    "\n",
    "Before starting working with different formats, let's see how we can create and read text files using Python buil-in function called **open**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "5f7ccded",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Open and write down a file\n",
    "f = open('text_file.txt', 'w')\n",
    "f.write('Hello')\n",
    "f.write('\\n')\n",
    "f.write('Bye')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "116186a1",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n",
      "Bye\n"
     ]
    }
   ],
   "source": [
    "# Open and read content of a file\n",
    "f = open('text_file.txt', 'r')\n",
    "content = f.read()\n",
    "f.close()\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "5d60bcc2",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line 0: Hello\n",
      "Line 1: Bye\n"
     ]
    }
   ],
   "source": [
    "# We can also simply split lines by using\n",
    "f = open('text_file.txt', 'r')\n",
    "lines = f.read().splitlines()\n",
    "f.close()\n",
    "# loop over the lines\n",
    "for idx, line in enumerate(lines): # enumerate provides returns the index and element\n",
    "    print(f'Line {idx}: {line}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "ef202e60",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Let's create a CSV (comma separated values) file\n",
    "header = \"Name,Age,Grade\\n\"\n",
    "rows = [\n",
    "    \"Jaume,30,8.9\\n\",\n",
    "    \"Francisco,25,7.1\\n\",\n",
    "    \"Elena,35,9.2\\n\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "f4d4930e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"grades.csv\", \"w\") as f:\n",
    "    f.write(header) # Write the header\n",
    "    \n",
    "    # Write each row of data\n",
    "    for row in rows:\n",
    "        f.write(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "35de8a4b",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Name', 'Age', 'Grade']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'students': [{'Name': 'Jaume', 'Age': '30', 'Grade': '8.9'},\n",
       "  {'Name': 'Francisco', 'Age': '25', 'Grade': '7.1'},\n",
       "  {'Name': 'Elena', 'Age': '35', 'Grade': '9.2'}]}"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"grades.csv\", \"r\") as f:\n",
    "    lines = f.read().splitlines()\n",
    "    \n",
    "header = lines.pop(0)\n",
    "header = header.split(',')\n",
    "\n",
    "print(header)\n",
    "\n",
    "grades = {'students': []}\n",
    "# create dictionary\n",
    "for line in lines:\n",
    "    student_dict = {}\n",
    "    values = line.split(',')\n",
    "    for idx, column in enumerate(header):\n",
    "        student_dict[column] = values[idx]\n",
    "    grades['students'].append(student_dict)\n",
    "    \n",
    "grades"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35dc1a74",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Basic Libraries II\n",
    "\n",
    "Another useful statement is **with**. It helps handling properly the resources within its reach, by closing them after its execution. It also makes the code more readable and maintainable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "474a10ea",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', 'Bye']\n"
     ]
    }
   ],
   "source": [
    "with open('text_file.txt', 'r') as f: # we don't have to close the open file, f.close()\n",
    "    lines = f.read().splitlines()\n",
    "    \n",
    "print(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557f7645",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Basic Libraries II\n",
    "\n",
    "JavaScript Object Notation (JSON) is a text-based format used for data storing and data interchange across different platforms and languages.\n",
    "\n",
    "Same as dictionaries, data is represented as key-value pairs. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3e215c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Basic Libraries II\n",
    "\n",
    "JavaScript Object Notation (JSON) is a text-based format used for data storing and data interchange across different platforms and languages.\n",
    "\n",
    "Same as dictionaries, data is represented as key-value pairs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "a85baeee",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'students': [{'name': 'Amelie', 'age': 35}, {'name': 'Edgar', 'age': 32}]}"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    "    \"students\": [\n",
    "        {\n",
    "            \"name\": \"Amelie\",\n",
    "            \"age\": 35\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Edgar\",\n",
    "            \"age\": 32\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "03372288",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Amelie', 'age': 35}, {'name': 'Edgar', 'age': 32}]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# other valid formats\n",
    "[\n",
    "    {\n",
    "        \"name\": \"Amelie\",\n",
    "        \"age\": 35\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Edgar\",\n",
    "        \"age\": 32\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "21363512",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Amelie', 137, True, None, {'age': 35}, [10, 12, 13]]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# other valid formats\n",
    "[\n",
    "    \"Amelie\",\n",
    "    137,\n",
    "    True, # within the json file True is equivalent to true\n",
    "    None, # within the json file None is equivalent to null\n",
    "    {\"age\": 35},\n",
    "    [10, 12, 13]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4f9fc6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Basic Libraries II\n",
    "\n",
    "To read and write down json files and manipulate them, we have the built-in json library within Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "550d6310",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "data = {\n",
    "    \"students\": [\n",
    "        {\n",
    "            \"name\": \"Amelie\",\n",
    "            \"age\": 35,\n",
    "            \"scolarship\": True\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Edgar\",\n",
    "            \"age\": 32,\n",
    "            \"scolarship\": None\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "with open('json_example.json', 'w') as f: # write down json\n",
    "    json.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "6094e3cf",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'students': [{'name': 'Amelie', 'age': 35, 'scolarship': True}, {'name': 'Edgar', 'age': 32, 'scolarship': None}]}\n"
     ]
    }
   ],
   "source": [
    "with open('json_example.json', 'r') as f:\n",
    "    json_data = json.load(f)\n",
    "    \n",
    "print(json_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ad57c3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Basic Libraries II\n",
    "\n",
    "Similar to JSON, Python includes a Pickle library. However, in contrast to the JSON format, Pickle is a Python-specific serialization format. The Pickle library provides tools to serialize Python objects, which involves transforming them into a stream of bytes. It also allows you to read these byte streams by deserializing them, transforming them back into their original Python objects.\n",
    "\n",
    "In contrast to the JSON format, the binary format is usually more compact and, therefore, more efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "5ab37f4f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.12448755 0.22450707 0.18077445 0.78055662 0.23850298 0.41243278\n",
      " 0.78928847 0.25504021 0.58352405 0.553139  ]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "data = np.random.rand(10)\n",
    "\n",
    "import pickle\n",
    "\n",
    "# Serializing (dumping) the object\n",
    "with open('data.pkl', 'wb') as f:\n",
    "    pickle.dump(data, f)\n",
    "\n",
    "# Deserializing (loading) the object\n",
    "with open('data.pkl', 'rb') as f:\n",
    "    loaded_data = pickle.load(f)\n",
    "\n",
    "print(loaded_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502f8a2f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Basic Libraries II\n",
    "\n",
    "**IMPORTANT**: Be extremely carefull when loading pickled data from untrusted sources. Pickles can execute arbitrary code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5826f2d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Basic Libraries II\n",
    "\n",
    "To work with **Parquet** files, you need either the **pyarrow** or **pandas** library. Parquet is a columnar storage format, meaning that each row represents a sample, and each column represents an attribute. This is a powerful format commonly used as a standard in platforms like **Hugging Face**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "72fce0ca",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      name  age\n",
      "0    Alice   25\n",
      "1      Bob   30\n",
      "2  Charlie   35\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd # if it is not working, simply uncomment the following line\n",
    "# !pip install pandas\n",
    "\n",
    "# Creating a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'name': ['Alice', 'Bob', 'Charlie'],\n",
    "    'age': [25, 30, 35]\n",
    "})\n",
    "\n",
    "# Writing DataFrame to Parquet file with Pandas\n",
    "df.to_parquet('data.parquet')\n",
    "\n",
    "# Reading DataFrame from Parquet file with Pandas\n",
    "df_loaded = pd.read_parquet('data.parquet')\n",
    "\n",
    "print(df_loaded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004bb3cc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Basic Libraries II\n",
    "\n",
    "When working with text, one of the most powerful tools is regular expressions, aka **regex**. With regex, you can perform complex pattern matching using wildcards and other special characters. Let's see how we could have handled session's four exercise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "0746e487",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['if', 'if']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "data = \"What a wonderful life if we could play more time.\"\n",
    "\n",
    "# Regex pattern to find 'if'\n",
    "pattern = 'if'\n",
    "\n",
    "# Search for the pattern\n",
    "matches = re.findall(pattern, data)\n",
    "\n",
    "print(matches) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef1d4ba",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Basic Libraries II\n",
    "\n",
    "Let's see how we could have handled session's four exercise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "37e73afc",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date: 20240101; Time: 123456; SN: 42; ver: 01; region: RegionName.txt\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Regex pattern, r in front of strings tell python to treat them as raw strings\n",
    "# we do this so slashes don't get interpret as scaping symbol\n",
    "pattern = r'(\\d{8})_(\\d{6})_SN(\\d+)_QUICKVIEW_VISUAL_([\\d_]+)_([A-Za-z0-9\\-_.]+)\\.txt' \n",
    "\n",
    "annotations = glob.glob('session_4/annotations/*.txt')\n",
    "\n",
    "for annotation in annotations:\n",
    "\n",
    "    # extract the file name\n",
    "    filename = os.path.basename(annotation)\n",
    "    \n",
    "    # Search and extract values\n",
    "    match = re.match(pattern, filename)\n",
    "    if match:\n",
    "        date, time, satellite_number, version, unique_region = match.groups()\n",
    "        print(f\"Date: {date}; Time: {time}; SN: {satellite_number}; ver: {version}; region: {unique_region}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "6b9fc572",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:3: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:3: SyntaxWarning: invalid escape sequence '\\d'\n",
      "C:\\Users\\Eva\\AppData\\Local\\Temp\\ipykernel_10860\\134246782.py:3: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  '''\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n(\\\\d{8}): Captures 8 digits (YYYYMMDD).\\n_(\\\\d{6}): Captures 6 digits (HHMMSS).\\n_SN(\\\\d+): Captures one or more digits.\\n_QUICKVIEW_VISUAL_([\\\\d_]+): Captures digits and underscores.\\n_([A-Za-z0-9\\\\-_.]+): Captures letters, numbers, hyphens (-), underscores (_), and dots (.).\\n\\\\.txt: Makes sure that the filename ends with .txt.\\n'"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern = r'(\\d{8})_(\\d{6})_SN(\\d+)_QUICKVIEW_VISUAL_([\\d_]+)_([A-Za-z0-9\\-_.]+)\\.txt'\n",
    "\n",
    "'''\n",
    "(\\d{8}): Captures 8 digits (YYYYMMDD).\n",
    "_(\\d{6}): Captures 6 digits (HHMMSS).\n",
    "_SN(\\d+): Captures one or more digits.\n",
    "_QUICKVIEW_VISUAL_([\\d_]+): Captures digits and underscores.\n",
    "_([A-Za-z0-9\\-_.]+): Captures letters, numbers, hyphens (-), underscores (_), and dots (.).\n",
    "\\.txt: Makes sure that the filename ends with .txt.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c2d658",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Basic Libraries II\n",
    "\n",
    "**Time** and **Datetime** are other two Python built-in libraries used in plenty of pipelines involving time measurements, timestamp creation and dates manipulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "1a90b193",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "9d51166e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1732099706.8522573\n"
     ]
    }
   ],
   "source": [
    "# Get current timestamp\n",
    "t = time.time() \n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "dd05bf5d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "time.sleep(1) # wait 1 second(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "32d7f7e7",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-20 11:48:27\n"
     ]
    }
   ],
   "source": [
    "# Formatting time, localtime where the code is run\n",
    "formatted_time = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime()) \n",
    "print(formatted_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "4ec76a98",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-20 11:48:27.887829\n",
      "2024-11-20 11:48:27\n",
      "2024-10-17 21:00:00\n",
      "2024-11-27 11:48:27.887829\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "# method now() gives us the current date and time\n",
    "now = datetime.now()\n",
    "print(now)\n",
    "\n",
    "# Similar to the strftime function in time, we can it from datetime\n",
    "formatted_now = now.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "print(formatted_now)\n",
    "\n",
    "# Parsing a string to a datetime object\n",
    "parsed_date = datetime.strptime(\"2024-10-17 21:00:00\", \"%Y-%m-%d %H:%M:%S\")\n",
    "print(parsed_date)\n",
    "\n",
    "# Adding a week using days with timedelta\n",
    "future_date = now + timedelta(days=7)\n",
    "print(future_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "adc567b3",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2024, 10, 17, 21)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_date.year, parsed_date.month, parsed_date.day, parsed_date.hour"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc70e0c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Basic Libraries II\n",
    "\n",
    "Let's now try to use them to order the annotations by date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "bc5ffd12",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datetime Object: 2024-01-01 12:34:56\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('20240101_123456_SN42_QUICKVIEW_VISUAL_01_RegionName.txt.txt',\n",
       "  datetime.datetime(2024, 1, 1, 12, 34, 56))]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import glob\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Regex pattern, r in front of strings tell python to treat them as raw strings\n",
    "# we do this so slashes don't get interpret as scaping symbol\n",
    "pattern = r'(\\d{8})_(\\d{6})_SN(\\d+)_QUICKVIEW_VISUAL_([\\d_]+)_([A-Za-z0-9\\-_.]+)\\.txt' \n",
    "\n",
    "annotations = glob.glob('session_4/annotations/*.txt')\n",
    "\n",
    "# let's create a dictionary where per each annotations we gather the datetime object\n",
    "ann_datetime = []\n",
    "\n",
    "for annotation in annotations:\n",
    "\n",
    "    # extract the file name\n",
    "    filename = os.path.basename(annotation)\n",
    "    \n",
    "    # Search and extract values\n",
    "    match = re.match(pattern, filename)\n",
    "    if match:\n",
    "        date, time, _, _, _ = match.groups()\n",
    "\n",
    "        # Put them together, e.g. \"20240101192856\"\n",
    "        datetime_str = date + time \n",
    "\n",
    "        # Parse the string into a datetime object\n",
    "        datetime_obj = datetime.strptime(datetime_str, \"%Y%m%d%H%M%S\")\n",
    "\n",
    "        # Output the datetime object\n",
    "        print(f\"Datetime Object: {datetime_obj}\")\n",
    "        \n",
    "        ann_datetime.append((filename, datetime_obj))\n",
    "\n",
    "ann_datetime\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "878a7793",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = np.argsort([date for name, date in ann_datetime])\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "22f9ba90",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20240101_123456_SN42_QUICKVIEW_VISUAL_01_RegionName.txt.txt\n"
     ]
    }
   ],
   "source": [
    "for i in indices:\n",
    "    print(ann_datetime[i][0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012aeb1b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise\n",
    "\n",
    "\n",
    "Reusing the same annotations we work with in the previous session, answer the following items using the libraries we saw today: \n",
    "\n",
    "1. How many annotations you have per month and year. Which month has more annotation files.\n",
    "2. Create a dictionary where each **key** is a month, and the corresponding **value** is a list containing all the annotation names with where their date corresponds to the month. \n",
    "    a. Save it following the json format, and load it again to check that everything is ok.\n",
    "    b. Save it this time using Pickle.\n",
    "    c. Instead of storing a list of all the annotation names happening that month, let's create for each annotation a dictionary with keys: name and date (using a datetime object).\n",
    "3. Print all the annotations from the oldest ones to the newest one during the seconf half of the 2024. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "2d27d2be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year-Month with the most annotations: (2024, 1), Count: 1\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import glob\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "pattern = r'(\\d{8})_(\\d{6})_SN(\\d+)_QUICKVIEW_VISUAL_([\\d_]+)_([A-Za-z0-9\\-_.]+)\\.txt'\n",
    "annotations = glob.glob('session_4/annotations/*.txt')\n",
    "ann_datetime = []\n",
    "for annotation in annotations:\n",
    "    filename = os.path.basename(annotation)\n",
    "    match = re.match(pattern, filename)\n",
    "    if match:\n",
    "        date, time, _, _, _ = match.groups()\n",
    "        datetime_str = date + time\n",
    "        datetime_obj = datetime.strptime(datetime_str, \"%Y%m%d%H%M%S\")\n",
    "        ann_datetime.append((filename, datetime_obj))\n",
    "\n",
    "from collections import Counter\n",
    "month_year_count = Counter((dt.year, dt.month) for _, dt in ann_datetime)\n",
    "\n",
    "most_common_month = month_year_count.most_common(1)[0]\n",
    "print(f\"Year-Month with the most annotations: {most_common_month[0]}, Count: {most_common_month[1]}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "33408047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded JSON data: {'2024-01': ['20240101_123456_SN42_QUICKVIEW_VISUAL_01_RegionName.txt.txt']}\n"
     ]
    }
   ],
   "source": [
    "annotations_by_month = {}\n",
    "for filename, dt in ann_datetime:\n",
    "    key = f\"{dt.year}-{dt.month:02d}\"\n",
    "    if key not in annotations_by_month:\n",
    "        annotations_by_month[key] = []\n",
    "    annotations_by_month[key].append(filename)\n",
    "with open('annotations_by_month.json', 'w') as json_file:\n",
    "    json.dump(annotations_by_month, json_file)\n",
    "\n",
    "with open('annotations_by_month.json', 'r') as json_file:\n",
    "    loaded_json_data = json.load(json_file)\n",
    "print(\"Loaded JSON data:\", loaded_json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "7af75cf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Pickle data: {'2024-01': ['20240101_123456_SN42_QUICKVIEW_VISUAL_01_RegionName.txt.txt']}\n"
     ]
    }
   ],
   "source": [
    "with open('annotations_by_month.pkl', 'wb') as pickle_file:\n",
    "    pickle.dump(annotations_by_month, pickle_file)\n",
    "with open('annotations_by_month.pkl', 'rb') as pickle_file:\n",
    "    loaded_pickle_data = pickle.load(pickle_file)\n",
    "print(\"Loaded Pickle data:\", loaded_pickle_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "6d66569d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2024-01': [{'name': '20240101_123456_SN42_QUICKVIEW_VISUAL_01_RegionName.txt.txt',\n",
       "   'date': datetime.datetime(2024, 1, 1, 12, 34, 56)}]}"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations_with_details = {}\n",
    "for filename, dt in ann_datetime:\n",
    "    key = f\"{dt.year}-{dt.month:02d}\"\n",
    "    if key not in annotations_with_details:\n",
    "        annotations_with_details[key] = []\n",
    "    annotations_with_details[key].append({'name': filename, 'date': dt})\n",
    "annotations_with_details "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "cd128738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Annotations from July to December 2024 (sorted from oldest to newest):\n"
     ]
    }
   ],
   "source": [
    "second_half_2024 = [item for item in ann_datetime if item[1].year == 2024 and item[1].month >= 7]\n",
    "second_half_2024_sorted = sorted(second_half_2024, key=lambda x: x[1])\n",
    "\n",
    "print(\"\\nAnnotations from July to December 2024 (sorted from oldest to newest):\")\n",
    "for filename, dt in second_half_2024_sorted:\n",
    "    print(f\"{dt}: {filename}\")"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
